{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d251fee0-1af2-4e61-8ef4-1241173ab2ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, IntegerType, StringType, BooleanType, DateType, DecimalType\n",
    "from pyspark.sql.functions import col, when, sum, avg, row_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26b66a61-11d0-4b13-95d3-a9e253ae58e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Criando a sessao\n",
    "\n",
    "spark = SparkSession.builder.appName(\"IPL Engenharia de dados\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f9ae792-ffcf-4913-9aff-ba0e9ec2cbe8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=2962905259980282#setting/sparkui/0424-203658-pb7gp5bt/driver-5601219293094703348\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=2962905259980282#setting/sparkui/0424-203658-pb7gp5bt/driver-5601219293094703348\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6aa35c7f-13e7-47de-a0fb-05609e24de41",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Criando o schema para a base de dados, e tipando cada coluna\n",
    "\n",
    "ball_by_ball_schema = StructType([\n",
    "    StructField(\"match_id\", IntegerType(), True),\n",
    "    StructField(\"over_id\", IntegerType(), True),\n",
    "    StructField(\"ball_id\", IntegerType(), True),\n",
    "    StructField(\"innings_no\", IntegerType(), True),\n",
    "    StructField(\"team_batting\", StringType(), True),\n",
    "    StructField(\"team_bowling\", StringType(), True),\n",
    "    StructField(\"striker_batting_position\", IntegerType(), True),\n",
    "    StructField(\"extra_type\", StringType(), True),\n",
    "    StructField(\"runs_scored\", IntegerType(), True),\n",
    "    StructField(\"extra_runs\", IntegerType(), True),\n",
    "    StructField(\"wides\", IntegerType(), True),\n",
    "    StructField(\"legbyes\", IntegerType(), True),\n",
    "    StructField(\"byes\", IntegerType(), True),\n",
    "    StructField(\"noballs\", IntegerType(), True),\n",
    "    StructField(\"penalty\", IntegerType(), True),\n",
    "    StructField(\"bowler_extras\", IntegerType(), True),\n",
    "    StructField(\"out_type\", StringType(), True),\n",
    "    StructField(\"caught\", BooleanType(), True),\n",
    "    StructField(\"bowled\", BooleanType(), True),\n",
    "    StructField(\"run_out\", BooleanType(), True),\n",
    "    StructField(\"lbw\", BooleanType(), True),\n",
    "    StructField(\"retired_hurt\", BooleanType(), True),\n",
    "    StructField(\"stumped\", BooleanType(), True),\n",
    "    StructField(\"caught_and_bowled\", BooleanType(), True),\n",
    "    StructField(\"hit_wicket\", BooleanType(), True),\n",
    "    StructField(\"obstructingfeild\", BooleanType(), True),\n",
    "    StructField(\"bowler_wicket\", BooleanType(), True),\n",
    "    StructField(\"match_date\", DateType(), True),\n",
    "    StructField(\"season\", IntegerType(), True),\n",
    "    StructField(\"striker\", IntegerType(), True),\n",
    "    StructField(\"non_striker\", IntegerType(), True),\n",
    "    StructField(\"bowler\", IntegerType(), True),\n",
    "    StructField(\"player_out\", IntegerType(), True),\n",
    "    StructField(\"fielders\", IntegerType(), True),\n",
    "    StructField(\"striker_match_sk\", IntegerType(), True),\n",
    "    StructField(\"strikersk\", IntegerType(), True),\n",
    "    StructField(\"nonstriker_match_sk\", IntegerType(), True),\n",
    "    StructField(\"nonstriker_sk\", IntegerType(), True),\n",
    "    StructField(\"fielder_match_sk\", IntegerType(), True),\n",
    "    StructField(\"fielder_sk\", IntegerType(), True),\n",
    "    StructField(\"bowler_match_sk\", IntegerType(), True),\n",
    "    StructField(\"bowler_sk\", IntegerType(), True),\n",
    "    StructField(\"playerout_match_sk\", IntegerType(), True),\n",
    "    StructField(\"battingteam_sk\", IntegerType(), True),\n",
    "    StructField(\"bowlingteam_sk\", IntegerType(), True),\n",
    "    StructField(\"keeper_catch\", BooleanType(), True),\n",
    "    StructField(\"player_out_sk\", IntegerType(), True),\n",
    "    StructField(\"matchdatesk\", DateType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "215b9ff5-a5f2-4dcd-b866-9c7accbd98e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Criando o dataframe baseado no schema que foi criado anteriormente, o dataframe vai ser criado com base em um csv, com o Header, e base Ã© carregada de um bucket S3\n",
    "ball_by_ball_df = spark.read.schema(ball_by_ball_schema).format('csv').option('header','true').load('s3://ipl-data-analysis-project/Ball_By_Ball.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05449dcc-0733-4444-b686-ac10a24e612f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Criando o schema para a base de dados, e tipando cada coluna; Criando o dataframe posteriormente\n",
    "match_schema = StructType([\n",
    "    StructField(\"match_sk\", IntegerType(), True),\n",
    "    StructField(\"match_id\", IntegerType(), True),\n",
    "    StructField(\"team1\", StringType(), True),\n",
    "    StructField(\"team2\", StringType(), True),\n",
    "    StructField(\"match_date\", DateType(), True),\n",
    "    StructField(\"season_year\", IntegerType(), True),\n",
    "    StructField(\"venue_name\", StringType(), True),\n",
    "    StructField(\"city_name\", StringType(), True),\n",
    "    StructField(\"country_name\", StringType(), True),\n",
    "    StructField(\"toss_winner\", StringType(), True),\n",
    "    StructField(\"match_winner\", StringType(), True),\n",
    "    StructField(\"toss_name\", StringType(), True),\n",
    "    StructField(\"win_type\", StringType(), True),\n",
    "    StructField(\"outcome_type\", StringType(), True),\n",
    "    StructField(\"manofmach\", StringType(), True),\n",
    "    StructField(\"win_margin\", IntegerType(), True),\n",
    "    StructField(\"country_id\", IntegerType(), True)\n",
    "])\n",
    "match_df = spark.read.schema(match_schema).format(\"csv\").option(\"header\",\"true\").load(\"s3://ipl-data-analysis-project/Match.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a1e7f40-5f7c-4e81-963c-472487167ac2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Criando o schema para a base de dados, e tipando cada coluna; Criando o dataframe posteriormente\n",
    "player_schema = StructType([\n",
    "    StructField(\"player_sk\", IntegerType(), True),\n",
    "    StructField(\"player_id\", IntegerType(), True),\n",
    "    StructField(\"player_name\", StringType(), True),\n",
    "    StructField(\"dob\", DateType(), True),\n",
    "    StructField(\"batting_hand\", StringType(), True),\n",
    "    StructField(\"bowling_skill\", StringType(), True),\n",
    "    StructField(\"country_name\", StringType(), True)\n",
    "])\n",
    "\n",
    "player_df = spark.read.schema(player_schema).format(\"csv\").option(\"header\",\"true\").load(\"s3://ipl-data-analysis-project/Player.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d98059f8-2fce-48ac-acdb-c174fc869355",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Criando o schema para a base de dados, e tipando cada coluna; Criando o dataframe posteriormente\n",
    "player_match_schema = StructType([\n",
    "    StructField(\"player_match_sk\", IntegerType(), True),\n",
    "    StructField(\"playermatch_key\", DecimalType(), True),\n",
    "    StructField(\"match_id\", IntegerType(), True),\n",
    "    StructField(\"player_id\", IntegerType(), True),\n",
    "    StructField(\"player_name\", StringType(), True),\n",
    "    StructField(\"dob\", DateType(), True),\n",
    "    StructField(\"batting_hand\", StringType(), True),\n",
    "    StructField(\"bowling_skill\", StringType(), True),\n",
    "    StructField(\"country_name\", StringType(), True),\n",
    "    StructField(\"role_desc\", StringType(), True),\n",
    "    StructField(\"player_team\", StringType(), True),\n",
    "    StructField(\"opposit_team\", StringType(), True),\n",
    "    StructField(\"season_year\", IntegerType(), True),\n",
    "    StructField(\"is_manofthematch\", BooleanType(), True),\n",
    "    StructField(\"age_as_on_match\", IntegerType(), True),\n",
    "    StructField(\"isplayers_team_won\", BooleanType(), True),\n",
    "    StructField(\"batting_status\", StringType(), True),\n",
    "    StructField(\"bowling_status\", StringType(), True),\n",
    "    StructField(\"player_captain\", StringType(), True),\n",
    "    StructField(\"opposit_captain\", StringType(), True),\n",
    "    StructField(\"player_keeper\", StringType(), True),\n",
    "    StructField(\"opposit_keeper\", StringType(), True)\n",
    "])\n",
    "\n",
    "player_match_df = spark.read.schema(player_match_schema).format(\"csv\").option(\"header\",\"true\").load(\"s3://ipl-data-analysis-project/Player_match.csv\")\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6467e06-3ce5-4d7a-9009-5d5e2d05583e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Utilizando a funÃ§Ã£o filter do pyspark para remover valores '0' das colunas especificadas (wides, noballs). Ou seja, filtrando/retirando todos os valores ao qual essas condiÃ§Ãµes forem verdadeiras.\n",
    "\n",
    "ball_by_ball_df = ball_by_ball_df.filter((col('wides') == 0) & (col('noballs') == 0))\n",
    "\n",
    "\n",
    "# Somando o total de corridas e a media de corridas\n",
    "\n",
    "total_and_avg_runs = ball_by_ball_df.groupBy('match_id', 'innings_no').agg(\n",
    "    sum('runs_scored').alias('total_runs'),\n",
    "    avg('runs_scored').alias('average_runs')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d23d1196-3559-4cf0-84bb-30881d3947d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# FunÃ§Ã£o de tela: Calculando o total de corridas para cada over em cada partida\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ipl_data_engineer_spark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
